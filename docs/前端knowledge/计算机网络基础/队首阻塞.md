## 队首阻塞

http1.0发送新的请求需要等前一个请求的响应收到

http1.1并行发送请求, 但是服务器会根据收到请求的顺序发送响应, 先收到先响应

解决办法: 

1. 多条tcp连接, 缺点; 耗费客户端和服务端资源
2. 复用一条连接

## http2

分帧: 消息由文本的形式转换成了二进制数据流的方式, 一条消息拆分成多个帧

组装: 二进制分帧的方式使请求和响应都是以数据流的方式并行发送, 客户端和服务器收到数据流之后, 根据编号组装起来

多路复用一条tcp连接

每个流(每个信道)可以分配优先级

大多数HTTP 连接的时间都很短，而且是突发性的，但TCP 只在长时间连接传输大块数据时效率才最高。HTTP 2.0 通过让所有数据流共用同一个连接，可以更有效地使用TCP 连接。



## 首部压缩

无损压缩算法会有个特性，数据越冗余，压缩效率越好。而首部中的很多字段是已知的，我们只要构造个请求，请求中带有首部的某个字段，经压缩再加密后的密文长度就会有所变化，然后不断构造猜测该字段的值，同时观察密文的长度，慢慢地确定首部字段的值。



算法: HPACK

首部表:

- 静态表(内置)
- 动态表

哈夫曼编码



服务器推送，此推送非彼推送，一开始以为，是不是以后可以抛弃轮询这种技术了？并不是，该轮询还是要轮询。那么，在开启keep-alive的情况下，轮询在HTTP/2中的性能没什么提升吗？也并不是。

在HTTP/1.x中首部是没有压缩的，gzip只会压缩body，HTTP/2提供了首部压缩方案。一般轮询请求首部，特别是cookie占用很多大部份空间，首部压缩使得整个HTTP数据包小了很多，传输也就会更快。

刚开始spdy提出的首部压缩方案比较简单粗暴，直接像压缩body那样压缩首部，这看起来好像没什么不妥，但是有安全隐患，会有受到CRIME式攻击的可能性。这种攻击方法简单说，就是不断地利用已知数据去探测密文，达到破解的目的。无损压缩算法会有个特性，数据越冗余，压缩效率越好。而首部中的很多字段是已知的，我们只要构造个请求，请求中带有首部的某个字段，经压缩再加密后的密文长度就会有所变化，然后不断构造猜测该字段的值，同时观察密文的长度，慢慢地确定首部字段的值。

```
GET /pwd=0 HTTP/1.1
Cookie: pwd=123

GET /pwd=1 HTTP/1.1
Cookie: pwd=123
```

我们会发现，前者的密文长度比后者长，这样就确定了“d”，再慢慢的猜测，达到破解的目的。

HTTP/2中抛弃了这种方案，用专门设计的HPACK。它是在服务器和客户端各维护一个“首部表”，表中用索引代表首部名，或者首部键-值对，上一次发送两端都会记住已发送过哪些首部，下一次发送只需要传输差异的数据，相同的数据直接用索引表示即可，另外还可以选择地对首部值压缩后再传输。按照这样的设计，两次轮询请求的首部基本是一样的，那之后的请求基本只需要发送几个索引就可以了。

![img](%E9%98%9F%E9%A6%96%E9%98%BB%E5%A1%9E-imgs/2015-10-27_562ee2ca87b49.jpg)

“首部表”有两种，一种是静态表，即HTTP/2协议内置了常用的一些首部名和首部键值对。另一种是动态表，保存自定义的首部或五花八门的键值对等，动态表可以通过`SETTINGS`帧的SETTINGS_HEADER_TABLE_SIZE规定大小。





- 二进制分帧层

  - HTTP 2.0 二进制分帧层，封装HTTP 消息并在客户端与服务器之间传输

  [![Alt text](https://raw.githubusercontent.com/zqjflash/http2-protocol/master/binary-frame-layout.png)](https://raw.githubusercontent.com/zqjflash/http2-protocol/master/binary-frame-layout.png)

  - HTTP2.0 将所有传输的信息分割为更小的消息和帧，并对它们采用二进制格式的编码。
  - 注：HTTPS 是二进制分帧的另一个典型示例：所有HTTP 消息都以透明的方式为我们编码和解码，不必对应用进行任何修改。HTTP2.0工作原理有点类似

- 流、消息和帧

  - 流：流是连接中的一个虚拟信道，可以承载双向的消息；每个流都有一个唯一的整数标识符（1、2…N）；
  - 消息：是指逻辑上的 HTTP 消息，比如请求、响应等，由一或多个帧组成。
  - 帧：HTTP 2.0 通信的最小单位，每个帧包含帧首部，至少也会标识出当前帧所属的流，承载着特定类型的数据，如 HTTP 首部、负荷，等等



https://www.cnblogs.com/hustdc/p/8487366.html

http协议的队首阻塞
1 队首阻塞

就是需要排队，队首的事情没有处理完的时候，后面的人都要等着。

2 http1.0的队首阻塞

对于同一个tcp连接，所有的http1.0请求放入队列中，只有前一个请求的响应收到了，然后才能发送下一个请求。

可见，http1.0的队首组塞发生在客户端。

3 http1.1的队首阻塞

对于同一个tcp连接，http1.1允许一次发送多个http1.1请求，也就是说，不必等前一个响应收到，就可以发送下一个请求，这样就解决了http1.0的客户端的队首阻塞。但是，http1.1规定，服务器端的响应的发送要根据请求被接收的顺序排队，也就是说，先接收到的请求的响应也要先发送。这样造成的问题是，如果最先收到的请求的处理时间长的话，响应生成也慢，就会阻塞已经生成了的响应的发送。也会造成队首阻塞。

可见，http1.1的队首阻塞发生在服务器端。

4 http2是怎样解决队首阻塞的

http2无论在客户端还是在服务器端都不需要排队，在同一个tcp连接上，有多个stream，由各个stream发送和接收http请求，各个steam相互独立，互不阻塞。

只要tcp没有人在用那么就可以发送已经生成的requst或者reponse的数据，在两端都不用等，从而彻底解决了http协议层面的队首阻塞问题。





建立多个TCP连接的确可以对上面的问题进行优化，但是建立多个TCP连接是十分耗费客户端和服务器端的资源的，每建立一个连接需要三次握手，1.5次RTT，在连接建立完后，长连接（或者叫连接复用）使得请求和响应完成后，连接不会立刻关闭，即使后面没有请求发送，服务器也必须维持着这么一些TCP连接，耗费不少服务器的资源。所以多个TCP连接的优化方式缺陷还是挺大的，最主要是耗费客户端和服务器端的资源
————————————————
版权声明：本文为CSDN博主「大力海棠」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/justinzengTM/article/details/105918883



HTTP/2优化
HTTP/2支持在一个TCP连接中并行发送多个请求和接收多个响应，无需等待，因为对HTTP消息进行二进制分帧的方式进行编码，客户端和服务器端之间的消息传递变成互不干扰的帧，可以交错发送，待接收完之后再组装成完整的消息。由此可见，在HTTP/2上客户端接收响应无需严格按照发送请求的顺序，服务器端发送响应也无需严格按照接收到请求的顺序，只要当前TCP连接可用，双方就可以互相发送消息。

二进制分帧
       与HTTP/1.1不同，HTTP/2将发送的消息由文本形式转换成了二进制数据流方式，也就是编码方式发生了改变。HTTP/2将消息帧编码成二进制格式，一条消息被拆分成多个帧，帧是最小的通信单位，

每个帧都有编号，这些二进制帧数据流到达另一端后再根据帧的编号进行组装。帧在客户端和服务器端的TCP连接上是双向传输的，以字节流的方式，互不干扰（因为编码和封装方式），可以交错发送，只要当前TCP连接可用，就可以发送请求和响应，消除了HTTP/1.1中请求和响应对应的关系，HTTP/1.1中一个TCP连接要严格按照顺序发送请求和接收响应，如果一个响应没有发送出去，那么后面的响应即使生成完毕，也必须等待。使用了HTTP/2进行通信，二进制分帧的方式使得请求和响应都是以数据流的方式并行发送，客户端和服务器端接收到数据流后，再根据帧的编号进行组装，得到完整的消息，以此解决队首阻塞问题。

并行处理
二进制分帧的方式还有一个好处就是能实现一个TCP连接的请求和响应复用，在一个连接上，客户端浏览器和服务器端可以不断向对方发送帧，一个请求或响应就是一个数据流，在每个流中交错发送帧给对方，即实现了并行处理。上面队首阻塞中的一个问题（或者说优化方案）是建立多个TCP连接来提升并行处理的能力，但是这种方式的缺点很明显，长连接的方式使得一直保持着多个TCP连接，会耗费客户端和服务器端的不少资源。在HTTP/2下将消息拆分成多个帧，以二进制编码交错发送，当客户端浏览器向服务器端发送数据流（一系列的帧）时，服务器也可以同时发送自己已生成的响应数据流，无需像HTTP/1.1那样请求与响应匹配，实现了并行发送多个交错请求和响应，之间互不干扰，并行处理，且只需在一个TCP连接上，减少资源负担。

到这里我已经把自己知道的HTTPS性能优化都总结了，上一篇日志是在网络层的优化，例如流量控制，启用慢启动。应用层优化的地方就很多了，长连接，多个TCP连接，队首阻塞问题和多个TCP连接耗费资源问题都在HTTP/2里得到解决，二进制分帧也提供了更好的并行处理。
————————————————
版权声明：本文为CSDN博主「大力海棠」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/justinzengTM/article/details/105918883